{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6969, 23)\n",
      "          Date    Year        Type    Country              State  \\\n",
      "0  15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
      "1  04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "2  02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "3  25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
      "4  14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
      "\n",
      "                           Location  Activity                 Name Sex  Age  \\\n",
      "0                     Bargara Beach  Swimming       Brooklyn Sauer   F   13   \n",
      "1                Old Man's, Waikiki   Surfing        Matthew White   M  NaN   \n",
      "2                    Rainbows, Oahu  Swimming                  NaN   F   11   \n",
      "3        Sandlnd Island, Jurian Bay       NaN               female   F   46   \n",
      "4  Vaitarna River, Palghar District   Fishing  Vicky Suresh Govari   M   32   \n",
      "\n",
      "   ...        Species                      Source  pdf href formula href  \\\n",
      "0  ...     Tiger shark      Yahoo News, 3/15/2024  NaN          NaN  NaN   \n",
      "1  ...  Tiger shark 8'          Surfer, 3/6/2024F  NaN          NaN  NaN   \n",
      "2  ...  3' to 4' shark  Hawaii News Now, 3/4/2024  NaN          NaN  NaN   \n",
      "3  ...     Tiger shark        WA Today, 2/26/2024  NaN          NaN  NaN   \n",
      "4  ...  Bull shark, 7'  Times of India, 2/14/2024  NaN          NaN  NaN   \n",
      "\n",
      "  Case Number Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
      "0         NaN           NaN            NaN         NaN         NaN  \n",
      "1         NaN           NaN            NaN         NaN         NaN  \n",
      "2         NaN           NaN            NaN         NaN         NaN  \n",
      "3         NaN           NaN            NaN         NaN         NaN  \n",
      "4         NaN           NaN            NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Index(['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity',\n",
      "       'Name', 'Sex', 'Age', 'Injury', 'Unnamed:11', 'Time', 'Species',\n",
      "       'Source', 'pdf', 'hrefformula', 'href', 'CaseNumber', 'CaseNumber.1',\n",
      "       'originalorder', 'Unnamed:21', 'Unnamed:22'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import data from xls\n",
    "og_df = pd.read_excel('GSAF5.xls')\n",
    "\n",
    "# Check for basic shape and some values\n",
    "print(og_df.shape)\n",
    "print(og_df.head(5))\n",
    "\n",
    "#Let's create a copy to work with and rename columns\n",
    "df = og_df.copy()\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this columns don't seem to hold relevant information for this project\n",
    "df.drop(columns=['Unnamed:21'], inplace=True)\n",
    "df.drop(columns=['Unnamed:22'], inplace=True)\n",
    "df.drop(columns=['Unnamed:11'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date               25\n",
      "Year               27\n",
      "Type               43\n",
      "Country            75\n",
      "State             507\n",
      "Location          590\n",
      "Activity          611\n",
      "Name              245\n",
      "Sex               604\n",
      "Age              3019\n",
      "Injury             60\n",
      "Time             3551\n",
      "Species          3157\n",
      "Source             44\n",
      "pdf               170\n",
      "hrefformula       150\n",
      "href              173\n",
      "CaseNumber        171\n",
      "CaseNumber.1      172\n",
      "originalorder     170\n",
      "dtype: int64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Let's drop duplicates and missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df.drop_duplicates(inplace=True))\n",
    "\n",
    "df.dropna(subset=[\"Date\"],axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      " Date             0\n",
      "Year             0\n",
      "Type             0\n",
      "Country          0\n",
      "State            0\n",
      "Location         0\n",
      "Activity         1\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              2\n",
      "Injury           1\n",
      "Time             2\n",
      "Species          7\n",
      "Source           0\n",
      "pdf              0\n",
      "hrefformula      0\n",
      "href             0\n",
      "CaseNumber       0\n",
      "CaseNumber.1     0\n",
      "originalorder    0\n",
      "dtype: int64\n",
      "After\n",
      " Date             0\n",
      "Year             0\n",
      "Type             0\n",
      "Country          0\n",
      "State            0\n",
      "Location         0\n",
      "Activity         0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "Injury           0\n",
      "Time             0\n",
      "Species          0\n",
      "Source           0\n",
      "pdf              0\n",
      "hrefformula      0\n",
      "href             0\n",
      "CaseNumber       0\n",
      "CaseNumber.1     0\n",
      "originalorder    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before\\n\", df.eq(\" \").sum())\n",
    "df = df[df!= \" \"] #Very low number of spaces so we can drop this outliers\n",
    "print(\"After\\n\", df.eq(\" \").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "2022.07.28  -  2022.7.28\n",
      "2022,94,39  -  2022.04.30\n",
      "2022,04.17  -  2022.04.17\n",
      "2022.04.1.2  -  2022.04.12\n",
      "2022.03.15.c  -  nan\n",
      "2022.03.15.b  -  2022.03.15\n",
      "nan  -  nan\n",
      "2022.01.06.R  -  2022,91,06.R\n",
      "2021.12.06.r  -  2021.12.06.R\n",
      "2021.10.16  -  2021.10.15\n",
      "2021.10.03.b  -  2021.10.04.b\n",
      "2021. 08.21  -  2021.08.21\n",
      "2021..08.07.b  -  2021.08.07.b\n",
      "2021.08.07.a  -  2021..08.07.a\n",
      "2021.02.20  -  2021.02.21\n",
      "2021.01.22.a  -  2021.01.22\n",
      "2020.12.02  -  2020.12.06\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "201810.19.a  -  2018.10.19.a\n",
      "2018.09.27  -  2018.08.27\n",
      "2018.07.11.a  -  2018.07.13.a\n",
      "2018.04.02  -  2018.04.03\n",
      "nan  -  nan\n",
      "2017/07.20.a  -  2017.07.20.a\n",
      "2017.06.06  -  2017.05.06\n",
      "2016.09.16  -  2016.09.15\n",
      "2015.01.24.b  -  2016.01.24.b\n",
      "2015.11.07  -  2015.12.23\n",
      "2015.10.28  -  2015.10.28.a\n",
      "2013.05.04  -  2014.05.04\n",
      "1994.12.09.c  -  1994.1.2.09.c\n",
      "1974.12.21  -  1974.21.21\n",
      "k  -  1971.04.05.b\n",
      "1967/07.05  -  1967.07.05\n",
      "1962.08.30.b  -  1962,08.30.b\n",
      "1961.09,06.R  -  1961.09.02.R\n",
      "1952.08.04  -  1952.08.05\n",
      "1951.12.15.R  -  1851.12.15.R\n",
      "nan  -  nan\n",
      "1919.00.00.R  -  1900.00.00.R\n",
      "1913.17.10.R  -  1913.07.10.R\n",
      "1911.07.31.T  -  1911.07.31.R\n",
      "1884.04.28.R  -  1884.04.38.R\n",
      "1874.06.18.R  -  1876.06.18.R\n",
      "1853.04.29  -  1853,94.29\n",
      "1808.05.01.R  -  1808.06.01.R\n",
      "nan  -  nan\n",
      "nan  -  nan\n",
      "5BC-Australia  -  5BC\n",
      "214BC-Tharsus  -  214BC\n",
      "336BC-Csrnathus  -  336BC\n",
      "493BC-PersianFleet  -  493BC\n",
      "725BC-vase  -  725/BC\n",
      "1010BC-Japan  -  1010BC\n",
      "4000.BC-Peru  -  4000BC\n",
      "ND-0157  -  ND-157\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row[\"CaseNumber\"] != row[\"CaseNumber.1\"]:\n",
    "        print(row[\"CaseNumber\"], \" - \", row[\"CaseNumber.1\"])\n",
    "\n",
    "#TODO Maybe we can drop both columns as I don't think they hold relevant information and have some mismatched information (typos/incorrect format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6944, 20)\n",
      "(6915, 20)\n"
     ]
    }
   ],
   "source": [
    "#Country , State , Location - We really only need one of these to identify the place, so lets drop all that have all 3 missing\n",
    "print(df.shape)\n",
    "df = df[df!= \" \"]\n",
    "df = df[(df[\"State\"].isna()==False) | (df[\"Country\"].isna()==False) | (df[\"Location\"].isna()==False)] #Removes all True|True|True which have na/na/na as the location\n",
    "print(df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
