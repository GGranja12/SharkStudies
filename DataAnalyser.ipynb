{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6969, 23)\n",
      "          Date    Year        Type    Country              State  \\\n",
      "0  15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
      "1  04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "2  02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "3  25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
      "4  14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
      "\n",
      "                           Location  Activity                 Name Sex  Age  \\\n",
      "0                     Bargara Beach  Swimming       Brooklyn Sauer   F   13   \n",
      "1                Old Man's, Waikiki   Surfing        Matthew White   M  NaN   \n",
      "2                    Rainbows, Oahu  Swimming                  NaN   F   11   \n",
      "3        Sandlnd Island, Jurian Bay       NaN               female   F   46   \n",
      "4  Vaitarna River, Palghar District   Fishing  Vicky Suresh Govari   M   32   \n",
      "\n",
      "   ...        Species                      Source  pdf href formula href  \\\n",
      "0  ...     Tiger shark      Yahoo News, 3/15/2024  NaN          NaN  NaN   \n",
      "1  ...  Tiger shark 8'          Surfer, 3/6/2024F  NaN          NaN  NaN   \n",
      "2  ...  3' to 4' shark  Hawaii News Now, 3/4/2024  NaN          NaN  NaN   \n",
      "3  ...     Tiger shark        WA Today, 2/26/2024  NaN          NaN  NaN   \n",
      "4  ...  Bull shark, 7'  Times of India, 2/14/2024  NaN          NaN  NaN   \n",
      "\n",
      "  Case Number Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
      "0         NaN           NaN            NaN         NaN         NaN  \n",
      "1         NaN           NaN            NaN         NaN         NaN  \n",
      "2         NaN           NaN            NaN         NaN         NaN  \n",
      "3         NaN           NaN            NaN         NaN         NaN  \n",
      "4         NaN           NaN            NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Index(['date', 'year', 'type', 'country', 'state', 'location', 'activity',\n",
      "       'name', 'sex', 'age', 'injury', 'unnamed:11', 'time', 'species',\n",
      "       'source', 'pdf', 'hrefformula', 'href', 'casenumber', 'casenumber.1',\n",
      "       'originalorder', 'unnamed:21', 'unnamed:22'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import data from xls\n",
    "og_df = pd.read_excel('GSAF5.xls')\n",
    "\n",
    "# Check for basic shape and some values\n",
    "print(og_df.shape)\n",
    "print(og_df.head(5))\n",
    "\n",
    "#Let's create a copy to work with and rename columns\n",
    "df = og_df.copy()\n",
    "df.columns = df.columns.str.replace(' ', '').str.lower()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this columns don't seem to hold relevant information for this project\n",
    "df.drop(columns=['unnamed:21'], inplace=True)\n",
    "df.drop(columns=['unnamed:22'], inplace=True)\n",
    "df.drop(columns=['unnamed:11'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               25\n",
      "year               27\n",
      "type               43\n",
      "country            75\n",
      "state             507\n",
      "location          590\n",
      "activity          611\n",
      "name              245\n",
      "sex               604\n",
      "age              3019\n",
      "injury             60\n",
      "time             3551\n",
      "species          3157\n",
      "source             44\n",
      "pdf               170\n",
      "hrefformula       150\n",
      "href              173\n",
      "casenumber        171\n",
      "casenumber.1      172\n",
      "originalorder     170\n",
      "dtype: int64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Let's drop duplicates and missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df.drop_duplicates(inplace=True))\n",
    "\n",
    "(df.dropna(subset=[\"date\"],axis=0,inplace=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      " date             0\n",
      "year             0\n",
      "type             0\n",
      "country          0\n",
      "state            0\n",
      "location         0\n",
      "activity         1\n",
      "name             0\n",
      "sex              0\n",
      "age              2\n",
      "injury           1\n",
      "time             2\n",
      "species          7\n",
      "source           0\n",
      "pdf              0\n",
      "hrefformula      0\n",
      "href             0\n",
      "casenumber       0\n",
      "casenumber.1     0\n",
      "originalorder    0\n",
      "dtype: int64\n",
      "After\n",
      " date             0\n",
      "year             0\n",
      "type             0\n",
      "country          0\n",
      "state            0\n",
      "location         0\n",
      "activity         0\n",
      "name             0\n",
      "sex              0\n",
      "age              0\n",
      "injury           0\n",
      "time             0\n",
      "species          0\n",
      "source           0\n",
      "pdf              0\n",
      "hrefformula      0\n",
      "href             0\n",
      "casenumber       0\n",
      "casenumber.1     0\n",
      "originalorder    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before\\n\", df.eq(\" \").sum())\n",
    "df = df[df!= \" \"] #Very low number of spaces so we can drop this outliers\n",
    "print(\"After\\n\", df.eq(\" \").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6944, 20)\n",
      "(6915, 20)\n",
      "country\n",
      "USA                   2538\n",
      "AUSTRALIA             1481\n",
      "SOUTH AFRICA           597\n",
      "NEW ZEALAND            144\n",
      "BAHAMAS                136\n",
      "                      ... \n",
      "PUERTO RICO              1\n",
      "RED SEA                  1\n",
      "Coral Sea                1\n",
      "BRITISH ISLES            1\n",
      "CEYLON (SRI LANKA)       1\n",
      "Name: count, Length: 225, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Country , State , Location - We really only need one of these to identify the place, so lets drop all that have all 3 missing\n",
    "print(df.shape)\n",
    "df = df[df!= \" \"]\n",
    "df = df[(df[\"state\"].isna()==False) | (df[\"country\"].isna()==False) | (df[\"location\"].isna()==False)] #Removes all True|True|True which have na/na/na as the location\n",
    "print(df.shape)\n",
    "print(df[\"country\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "USA             2538\n",
      "AUSTRALIA       1481\n",
      "SOUTH AFRICA     597\n",
      "NEW ZEALAND      144\n",
      "BAHAMAS          136\n",
      "Name: count, dtype: int64\n",
      "(6915, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_five = df[\"country\"].value_counts().head(5)\n",
    "print(top_five)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "FL             1179\n",
      "HI              341\n",
      "CA              323\n",
      "SC              172\n",
      "NC              121\n",
      "TX               78\n",
      "NJ               57\n",
      "NY               48\n",
      "OR               31\n",
      "VA               19\n",
      "LA               18\n",
      "MA               18\n",
      "GA               17\n",
      "AL               17\n",
      "Puerto Rico      17\n",
      "Name: count, dtype: int64\n",
      "2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\709207919.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mini_df[\"state\"] = mini_df[\"state\"].str.strip()\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\709207919.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  mini_df[\"state\"].replace(us_states_codes, inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\709207919.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mini_df[\"state\"].replace(us_states_codes, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "mini_df = df[df[\"country\"] == \"USA\"]\n",
    "\n",
    "#print(mini_df.State.value_counts())\n",
    "\n",
    "us_states_codes = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "#state_series = mini_df[\"State\"].value_counts(dropna=False)\n",
    "\n",
    "mini_df[\"state\"] = mini_df[\"state\"].str.strip()\n",
    "\n",
    "mini_df[\"state\"].replace(us_states_codes, inplace=True)\n",
    "\n",
    "#disregard states with less that 10 occurences (outliers)\n",
    "state_counts = mini_df[\"state\"].value_counts(dropna=False)\n",
    "\n",
    "states_to_keep = state_counts[state_counts > 10].index\n",
    "# Filter the DataFrame\n",
    "USA_df = mini_df[mini_df[\"state\"].isin(states_to_keep)]\n",
    "\n",
    "print(USA_df[\"state\"].value_counts(dropna=False))\n",
    "print(USA_df[\"state\"].value_counts().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1179, 20)\n",
      "type\n",
      "Unprovoked             982\n",
      "Provoked               101\n",
      "Invalid                 68\n",
      "Watercraft              13\n",
      "Sea Disaster             6\n",
      "Questionable             4\n",
      "Unconfirmed              1\n",
      "Under investigation      1\n",
      "Name: count, dtype: int64\n",
      "2000 -> 35\n",
      "2001 -> 38\n",
      "2002 -> 31\n",
      "2003 -> 45\n",
      "2004 -> 12\n",
      "2005 -> 24\n",
      "2006 -> 28\n",
      "2007 -> 39\n",
      "2008 -> 37\n",
      "2009 -> 20\n",
      "2010 -> 18\n",
      "2011 -> 16\n",
      "2012 -> 32\n",
      "2013 -> 27\n",
      "2014 -> 33\n",
      "2015 -> 33\n",
      "2016 -> 34\n",
      "2017 -> 34\n",
      "2018 -> 17\n",
      "2019 -> 26\n",
      "2020 -> 23\n",
      "2021 -> 30\n",
      "2022 -> 24\n",
      "2023 -> 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>injury</th>\n",
       "      <th>time</th>\n",
       "      <th>species</th>\n",
       "      <th>source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>hrefformula</th>\n",
       "      <th>href</th>\n",
       "      <th>casenumber</th>\n",
       "      <th>casenumber.1</th>\n",
       "      <th>originalorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, year, type, country, state, location, activity, name, sex, age, injury, time, species, source, pdf, hrefformula, href, casenumber, casenumber.1, originalorder]\n",
       "Index: []"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Florida Dataframe\n",
    "\n",
    "FL_df = mini_df[mini_df[\"state\"] == \"FL\"]\n",
    "print(FL_df.shape)\n",
    "\n",
    "print(FL_df.type.value_counts())\n",
    "#print(FL_df.year.value_counts())\n",
    "\n",
    "years = FL_df.year.value_counts()\n",
    "\n",
    "for i in range(2000,2024):\n",
    "    print(f\"{i} -> {years[i]}\")\n",
    "    \n",
    "FL_df.head(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.62745098039215\n",
      "65.51724137931035\n",
      "64.58333333333334\n",
      "80.35714285714286\n",
      "34.285714285714285\n",
      "47.05882352941176\n",
      "53.84615384615385\n",
      "60.0\n",
      "62.71186440677966\n",
      "48.78048780487805\n",
      "47.368421052631575\n",
      "33.33333333333333\n",
      "50.0\n",
      "45.0\n",
      "53.2258064516129\n",
      "45.20547945205479\n",
      "52.307692307692314\n",
      "52.307692307692314\n",
      "40.476190476190474\n",
      "46.42857142857143\n",
      "53.48837209302325\n",
      "58.82352941176471\n",
      "48.97959183673469\n",
      "51.11111111111111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "us = USA_df.year.value_counts()\n",
    "florida = FL_df.year.value_counts()\n",
    "\n",
    "i = 2000\n",
    "\n",
    "for i in range(2000,2024):\n",
    "    print(florida[i]/us[i]*100)\n",
    "\n",
    "# this refers to the percent of shark attacks in the USA that happened in florida from 2000 onwards\n",
    "\n",
    "# USA_df - already only has the USA values in it\n",
    "# FL_df - already only has the FL values in it\n",
    "# df - is the main dataframe with all values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "New Smyrna Beach, Volusia County                             191\n",
       "Daytona Beach, Volusia County                                 31\n",
       "Ponce Inlet, Volusia County                                   28\n",
       "Melbourne Beach, Brevard County                               20\n",
       "Cocoa Beach, Brevard  County                                  18\n",
       "                                                            ... \n",
       "Quarter mile south of Ponce de Leon Inlet, Volusia County      1\n",
       "Off Zelda Boulevard, Daytona Beach, Volusia Countyy            1\n",
       "Tigertail Beach, Collier County                                1\n",
       "Marco Island, Collier County                                   1\n",
       "Mosquito Inlet (Ponce Inlet), Volusia County                   1\n",
       "Name: count, Length: 551, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL_df.location.value_counts()\n",
    "# clear major location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 20)\n",
      "(1126, 20)\n",
      "activity\n",
      "Surfing                         415\n",
      "Swimming                        151\n",
      "Wading                           76\n",
      "Fishing                          46\n",
      "Standing                         41\n",
      "                               ... \n",
      "Standing alongside surfboard      1\n",
      "Standing / surfing                1\n",
      "Swimming / Body surfing           1\n",
      "Surfing / Wading                  1\n",
      "Canoeing                          1\n",
      "Name: count, Length: 213, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fatal = FL_df[FL_df[\"injury\"].str.lower().str.contains('fatal', na=False)]\n",
    "non_fatal = FL_df[~FL_df[\"injury\"].str.lower().str.contains('fatal', na=False)]\n",
    "\n",
    "#print(fatal.injury.value_counts()) \n",
    "print(fatal.shape) #53\n",
    "#print(non_fatal.injury.value_counts())\n",
    "print(non_fatal.shape) #1126\n",
    "\n",
    "#print(FL_df.type.value_counts())\n",
    "#print(FL_df.species.value_counts())\n",
    "#print(FL_df.location.value_counts())\n",
    "#print(FL_df.activity.value_counts())\n",
    "\n",
    "print(FL_df.activity.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\964545945.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].fillna(\"Unknown\")\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\964545945.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].str.replace(\",\" , \"\")\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\964545945.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].str.replace(\"?\" , \"\")\n"
     ]
    }
   ],
   "source": [
    "df_final_activities_US = FL_df\n",
    "df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].fillna(\"Unknown\")\n",
    "\n",
    "print(df_final_activities_US[\"activity\"].isna().sum())\n",
    "\n",
    "df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].str.replace(\",\" , \"\")\n",
    "df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].str.replace(\"?\" , \"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_activity(activity):\n",
    "    # Convert the activity to lowercase and split into words\n",
    "    words = activity.lower().split()\n",
    "    # Check for the exact words and replace the activity's value by a broader category\n",
    "    if \"fishing\" in words:\n",
    "        return \"Fishing\"\n",
    "    elif \"spearfishing\" in words:\n",
    "        return \"Fishing\"\n",
    "    elif \"fisherman\" in words:\n",
    "        return \"Fishing\"\n",
    "    elif \"surfing\" in words:\n",
    "        return \"Surfing\"\n",
    "    elif \"swimming\" in words:\n",
    "        return \"Swimming\"\n",
    "    elif \"wading\" in words:\n",
    "        return \"Wading\"\n",
    "    elif \"floating\" in words:\n",
    "        return \"Floating\"\n",
    "    elif \"diving\" in words:\n",
    "        return \"Diving\"\n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15984\\1469196261.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].apply(replace_activity)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "activity\n",
       "Surfing                        455\n",
       "Swimming                       174\n",
       "Fishing                        117\n",
       "Wading                          83\n",
       "Unknown                         75\n",
       "                              ... \n",
       "Crouching in 2' of water         1\n",
       "Playing soccer in the water      1\n",
       "Shrimping                        1\n",
       "Playing on a sandbar             1\n",
       "Canoeing                         1\n",
       "Name: count, Length: 109, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to the Series\n",
    "df_final_activities_US[\"activity\"] = df_final_activities_US[\"activity\"].apply(replace_activity)\n",
    "\n",
    "df_final_activities_US[\"activity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "Surfing                        455\n",
       "Swimming                       174\n",
       "Fishing                        117\n",
       "Wading                          83\n",
       "Unknown                         75\n",
       "                              ... \n",
       "Crouching in 2' of water         1\n",
       "Playing soccer in the water      1\n",
       "Shrimping                        1\n",
       "Playing on a sandbar             1\n",
       "Canoeing                         1\n",
       "Name: count, Length: 109, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL_df[\"activity\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
